{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version III - Massive data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from InitialSetup.ipynb\n",
      "Num GPUs Available:  1\n",
      "Total images in validatation dataset:  12630\n",
      "(32, 32, 3) (43,)\n",
      "Total images in dataset:  39209\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "\n",
    "#pip install tensorflow-addons\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from InitialSetup import dataset, BATCH_SIZE, tf, prepare_callbacks, model_VI, show_history, test_dataset, AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_brightness(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.0, 1.0, 1.0, 0.1, 3.0),0,1)\n",
    "    return img, label\n",
    "\n",
    "def process_saturation(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.0, 1.0, 3.0, 1.0, 1.0),0,1)\n",
    "    return img, label\n",
    "\n",
    "def process_contrast(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tf.image.random_contrast(image, lower=0.1, upper=3.0, seed=None), 0, 1)\n",
    "    return img, label\n",
    "\n",
    "def process_hue(image, label):\n",
    "    \n",
    "    img = tf.image.random_hue(image, max_delta=0.2, seed=None)\n",
    "    return img, label\n",
    "\n",
    "def process_rotate(image, label):\n",
    "    \n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    return img, label\n",
    "\n",
    "def process_shear(image, label):\n",
    "    \n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    sx = tf.random.uniform(shape=(), minval=-0.1, maxval=0.1, dtype=tf.dtypes.float32)\n",
    "    img = tfa.image.transform(img, [1, sx, -sx*32,   0,1,0,  0,0])\n",
    "    return img, label\n",
    "\n",
    "def process_translate(image, label):\n",
    "\n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    tx = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)\n",
    "    ty = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)  \n",
    "    img = tfa.image.translate(img, [tx,ty])\n",
    "    return img, label\n",
    "\n",
    "def process_crop(image, label):\n",
    "    \n",
    "    c = tf.random.uniform(shape=(), minval=24, maxval=32, dtype=tf.dtypes.float32)\n",
    "    img = tf.image.random_crop(image, size=[c,c,3])\n",
    "    img = tf.image.resize(img ,size= [32,32])\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataSoloV3 = dataset\n",
    "# color ops\n",
    "dataSoloV3 = dataSoloV3.map(process_brightness)\n",
    "dataSoloV3 = dataSoloV3.concatenate(dataset.map(process_contrast))\n",
    "dataSoloV3 = dataSoloV3.concatenate(dataset.map(process_hue))\n",
    "dataSoloV3 = dataSoloV3.concatenate(dataset.map(process_saturation))\n",
    "\n",
    "#geometry ops\n",
    "dataSoloV3 = dataSoloV3.concatenate(dataset.map(process_rotate))\n",
    "dataSoloV3 = dataSoloV3.concatenate(dataset.map(process_shear))\n",
    "dataSoloV3 = dataSoloV3.concatenate(dataset.map(process_translate))\n",
    "dataSoloV3 = dataSoloV3.concatenate(dataset.map(process_crop))\n",
    "\n",
    "dataSoloV3_size = tf.data.experimental.cardinality(dataSoloV3).numpy()\n",
    "\n",
    "dataSoloV3 = dataSoloV3.cache()\n",
    "dataSoloV3 = dataSoloV3.shuffle(buffer_size = dataSoloV3_size)\n",
    "dataSoloV3 = dataSoloV3.batch(batch_size = BATCH_SIZE)\n",
    "dataSoloV3 = dataSoloV3.prefetch(buffer_size = AUTOTUNE)\n",
    "dataSoloV3 = dataSoloV3.repeat()\n",
    "\n",
    "train_size = int(0.8* dataSoloV3_size)\n",
    "val_size = int(0.2* dataSoloV3_size)\n",
    "\n",
    "train_dataset = dataSoloV3.take(train_size)\n",
    "val_dataset = dataSoloV3.skip(train_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup model and save place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelV3 = model_VI(43, 32, 3)\n",
    "\n",
    "file_pathV3 = './Networks/MassiveDataAugmentation.ckpt'\n",
    "\n",
    "callbacksV3 = prepare_callbacks(file_pathV3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3920/3920 [==============================] - 190s 30ms/step - loss: 1.8308 - accuracy: 0.5210 - val_loss: 0.1399 - val_accuracy: 0.9635\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96351, saving model to ./Networks\\MassiveDataAugmentation.ckpt\n",
      "Epoch 2/20\n",
      "3920/3920 [==============================] - 117s 30ms/step - loss: 0.2260 - accuracy: 0.9343 - val_loss: 0.0525 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.96351 to 0.98603, saving model to ./Networks\\MassiveDataAugmentation.ckpt\n",
      "Epoch 3/20\n",
      "3920/3920 [==============================] - 118s 30ms/step - loss: 0.1150 - accuracy: 0.9658 - val_loss: 0.0398 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.98603 to 0.99025, saving model to ./Networks\\MassiveDataAugmentation.ckpt\n",
      "Epoch 4/20\n",
      "3920/3920 [==============================] - 117s 30ms/step - loss: 0.0805 - accuracy: 0.9761 - val_loss: 0.0218 - val_accuracy: 0.9944\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.99025 to 0.99439, saving model to ./Networks\\MassiveDataAugmentation.ckpt\n",
      "Epoch 5/20\n",
      "3920/3920 [==============================] - 117s 30ms/step - loss: 0.0598 - accuracy: 0.9821 - val_loss: 0.0176 - val_accuracy: 0.9955\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.99439 to 0.99546, saving model to ./Networks\\MassiveDataAugmentation.ckpt\n",
      "Epoch 6/20\n",
      "3920/3920 [==============================] - 117s 30ms/step - loss: 0.0496 - accuracy: 0.9846 - val_loss: 0.0191 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.99546\n",
      "Epoch 7/20\n",
      "3920/3920 [==============================] - 117s 30ms/step - loss: 0.0447 - accuracy: 0.9867 - val_loss: 0.0188 - val_accuracy: 0.9963\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.99546 to 0.99632, saving model to ./Networks\\MassiveDataAugmentation.ckpt\n",
      "Epoch 8/20\n",
      "3920/3920 [==============================] - 116s 30ms/step - loss: 0.0406 - accuracy: 0.9879 - val_loss: 0.0244 - val_accuracy: 0.9938\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.99632\n",
      "Epoch 9/20\n",
      "3920/3920 [==============================] - 117s 30ms/step - loss: 0.0362 - accuracy: 0.9891 - val_loss: 0.0206 - val_accuracy: 0.9944\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.99632\n",
      "Epoch 10/20\n",
      "3920/3920 [==============================] - 117s 30ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 0.0144 - val_accuracy: 0.9967\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.99632 to 0.99673, saving model to ./Networks\\MassiveDataAugmentation.ckpt\n",
      "Epoch 11/20\n",
      "3920/3920 [==============================] - 116s 30ms/step - loss: 0.0298 - accuracy: 0.9907 - val_loss: 0.0092 - val_accuracy: 0.9975\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.99673 to 0.99753, saving model to ./Networks\\MassiveDataAugmentation.ckpt\n",
      "Epoch 12/20\n",
      "3920/3920 [==============================] - 117s 30ms/step - loss: 0.0287 - accuracy: 0.9913 - val_loss: 0.0079 - val_accuracy: 0.9980\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.99753 to 0.99798, saving model to ./Networks\\MassiveDataAugmentation.ckpt\n",
      "Epoch 13/20\n",
      "3920/3920 [==============================] - 116s 30ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 0.0238 - val_accuracy: 0.9955\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.99798\n",
      "Epoch 14/20\n",
      "3920/3920 [==============================] - 117s 30ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.0132 - val_accuracy: 0.9962\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.99798\n",
      "Epoch 15/20\n",
      "3920/3920 [==============================] - 117s 30ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0101 - val_accuracy: 0.9974\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.99798\n",
      "Epoch 16/20\n",
      "3920/3920 [==============================] - 116s 29ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.99798 to 0.99844, saving model to ./Networks\\MassiveDataAugmentation.ckpt\n",
      "Epoch 17/20\n",
      "3920/3920 [==============================] - 118s 30ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.0055 - val_accuracy: 0.9986\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.99844 to 0.99858, saving model to ./Networks\\MassiveDataAugmentation.ckpt\n",
      "Epoch 18/20\n",
      "3920/3920 [==============================] - 118s 30ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.0069 - val_accuracy: 0.9986\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.99858 to 0.99860, saving model to ./Networks\\MassiveDataAugmentation.ckpt\n",
      "Epoch 19/20\n",
      "3920/3920 [==============================] - 117s 30ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0084 - val_accuracy: 0.9979\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99860\n",
      "Epoch 20/20\n",
      "3920/3920 [==============================] - 115s 29ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.99860\n"
     ]
    }
   ],
   "source": [
    "modelV3 = model_VI(43, 32, 3)\n",
    "\n",
    "file_pathV3 = './Networks/MassiveDataAugmentation.ckpt'\n",
    "\n",
    "callbacksV3 = prepare_callbacks(file_pathV3)\n",
    "\n",
    "historyV3 = modelV3.fit(train_dataset, steps_per_epoch = train_size/BATCH_SIZE,\n",
    "          epochs=20, \n",
    "          validation_data = val_dataset, \n",
    "          validation_steps = val_size/BATCH_SIZE,\n",
    "          callbacks = callbacksV3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the learning history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(historyV3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights from file and test with validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 - 3s - loss: 0.0262 - accuracy: 0.9922\n",
      "980/980 - 41s - loss: 0.0097 - accuracy: 0.9976\n"
     ]
    }
   ],
   "source": [
    "modelV3.load_weights(file_pathV3)\n",
    "\n",
    "evalV3 = modelV3.evaluate(test_dataset, verbose=2)\n",
    "valV3 = modelV3.evaluate(val_dataset, steps=val_size/BATCH_SIZE, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0da461f411a8ab525eeaf0c070efcfd41d80a0fa07fe716f6def51d18e38691"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
